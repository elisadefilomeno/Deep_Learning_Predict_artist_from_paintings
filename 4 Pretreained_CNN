{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A2I6vjZl8PGL"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","from tqdm import tqdm, tqdm_notebook\n","import random\n","from google.colab import drive\n","from google.colab import files\n","import shutil\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.initializers import *\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from numpy.random import seed\n","import pickle\n","seed(1)\n","tf.random.set_seed(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29203,"status":"ok","timestamp":1681636376974,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"},"user_tz":-120},"id":"_1qxHZCW8dUG","outputId":"073fe42a-daf2-47df-ee5e-458b8063e95d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount drive \n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3vzWUn28fAb"},"outputs":[],"source":["root_path = \"/content/drive/Shareddrives/[Deep Learning Project]\"\n","dataset_dir = os.path.join(root_path, \"Dataset\")\n","balanced_train_dir = os.path.join(dataset_dir, 'balanced_train') # We're using the balanced dataset\n","test_dir = os.path.join(dataset_dir, 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oARPyt998gzh"},"outputs":[],"source":["#Set the parameter used to load the dataset\n","BATCH_SIZE = 64\n","IMAGE_HEIGHT = 180\n","IMAGE_WIDTH = 180"]},{"cell_type":"markdown","source":["#Creation of the training, validation and test set\n","\n","We exploit the directory hierarchy of our dataset to infer the classes from the\n","name of the directories, more details are present in the report about the choices taken."],"metadata":{"id":"2FOUs8wyAThd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28978,"status":"ok","timestamp":1681636405949,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"},"user_tz":-120},"id":"NckhVQ1j8jdt","outputId":"b830dd52-db37-413a-8242-20cda68f3be2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8100 files belonging to 18 classes.\n","Using 7290 files for training.\n","Found 8100 files belonging to 18 classes.\n","Using 810 files for validation.\n","Found 1112 files belonging to 18 classes.\n"]}],"source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","train_dataset = image_dataset_from_directory(\n","    balanced_train_dir,\n","    labels='inferred', \n","    label_mode='categorical',\n","    class_names=None, \n","    color_mode='rgb',\n","    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    validation_split=0.1,\n","    subset=\"training\",\n","    shuffle=True,\n","    seed=1024)\n","\n","validation_dataset = image_dataset_from_directory(\n","    balanced_train_dir,\n","    labels='inferred', \n","    label_mode='categorical',\n","    class_names=None, \n","    color_mode='rgb',\n","    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    validation_split=0.1,\n","    subset=\"validation\",\n","    shuffle=True,\n","    seed=1024)\n","\n","test_dataset = image_dataset_from_directory(\n","    test_dir,\n","    labels='inferred', \n","    label_mode='categorical',\n","    class_names=None, \n","    color_mode='rgb',\n","    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","    batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","source":["Let's import the pre-trained model:"],"metadata":{"id":"8A7UhCQ8q54K"}},{"cell_type":"code","source":["from tensorflow.keras.applications import VGG16\n","\n","conv_base = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False,\n","    input_shape=(180, 180, 3))"],"metadata":{"id":"GUBPvTz8s7ol","executionInfo":{"status":"ok","timestamp":1681636410279,"user_tz":-120,"elapsed":4341,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1578fcd8-05a7-4155-a113-27e1285bf49c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqfV_lzOtFQ2","executionInfo":{"status":"ok","timestamp":1681636410279,"user_tz":-120,"elapsed":21,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"}},"outputId":"5e5583fb-8b4e-46ef-a030-3de392bb29f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","print('This is the number of trainable weights '\n","      'before freezing the conv base:', sum(np.prod(x.shape) for x in conv_base.trainable_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psPiP6XrtqKH","executionInfo":{"status":"ok","timestamp":1681636410279,"user_tz":-120,"elapsed":14,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"}},"outputId":"052c6499-4776-4d52-e5fe-b0fd70c41966"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the number of trainable weights before freezing the conv base: 14714688\n"]}]},{"cell_type":"markdown","source":["# Feature extraction"],"metadata":{"id":"NYc8_SR5sHhO"}},{"cell_type":"markdown","source":["Let's freeze all the layers in the convolution base:"],"metadata":{"id":"yz1BJ9oxrS3u"}},{"cell_type":"code","source":["conv_base.trainable = False"],"metadata":{"id":"jKhE1n0jvNhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('This is the number of trainable weights '\n","      'after freezing the conv base:', sum(np.prod(x.shape) for x in conv_base.trainable_weights))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EABO6hq4tqGv","executionInfo":{"status":"ok","timestamp":1681636410280,"user_tz":-120,"elapsed":12,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"}},"outputId":"624faeb9-33ab-4a40-a738-905c8bc3bd77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the number of trainable weights after freezing the conv base: 0\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","data_augmentation = keras.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.2),\n","])"],"metadata":{"id":"aByI-Q19tp-n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we define the classifier that we will add on top of the convolutional base:"],"metadata":{"id":"OtImbOF6rula"}},{"cell_type":"code","source":["inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = layers.Rescaling(1./255)(inputs)\n","x = keras.applications.vgg16.preprocess_input(x)\n","x = conv_base(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(256, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(18, activation=\"softmax\")(x)\n","\n","optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n","\n","model = keras.Model(inputs, outputs)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n"],"metadata":{"id":"Q9oAAi2OtG_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyB0BiJHvA3U","executionInfo":{"status":"ok","timestamp":1681636410937,"user_tz":-120,"elapsed":9,"user":{"displayName":"FABIANO PILIA","userId":"16552442109143948924"}},"outputId":"ef6ced71-1cca-48e0-a141-61e6ffb9d832"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 180, 180, 3)]     0         \n","                                                                 \n"," rescaling (Rescaling)       (None, 180, 180, 3)       0         \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 180, 180, 3)      0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," tf.nn.bias_add (TFOpLambda)  (None, 180, 180, 3)      0         \n","                                                                 \n"," vgg16 (Functional)          (None, 5, 5, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 12800)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               3277056   \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 18)                4626      \n","                                                                 \n","=================================================================\n","Total params: 17,996,370\n","Trainable params: 3,281,682\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**Let's add Keras callbacks:**\n","\n","*   Early stopping"],"metadata":{"id":"NjPmTOXPArME"}},{"cell_type":"code","source":["callbacks_list = [\n","    keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=8)\n","]"],"metadata":{"id":"fssRp_AXvkL4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the network:"],"metadata":{"id":"60eQpuy1BHZ5"}},{"cell_type":"code","source":["\n","history = model.fit(train_dataset,\n","                    epochs=50,\n","                    callbacks=callbacks_list,\n","                    validation_data=validation_dataset\n","                    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7Np0fkDv8RT","outputId":"860c37c2-146b-4260-c6f5-ecb643730622"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","114/114 [==============================] - ETA: 0s - loss: 2.9997 - accuracy: 0.0554 "]}]},{"cell_type":"markdown","source":["# Evaluation of the model"],"metadata":{"id":"8vfRn_E6_57v"}},{"cell_type":"markdown","source":["In the following cells we've evaluated the model obtaining its loss and accuracy."],"metadata":{"id":"3H_8ykWmBRcZ"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","i = np.argmax(val_acc)\n","x_min = epochs[i]\n","y_min = val_acc[i]\n","plt.plot(x_min, y_min,'g',marker='o', label=\"Maximum validation accuracy\")\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","\n","i = np.argmin(val_loss)\n","x_min = epochs[i]\n","y_min = val_loss[i]\n","plt.plot(x_min, y_min,'g',marker='o', label=\"Minimum validation loss\")\n","\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"Eclu8k_6x8eI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluate the model on the test set\n","test_loss, test_acc = model.evaluate(test_dataset)\n","\n","#Save the rusults in the history dictionary\n","history.history[\"test_loss\"] = test_loss\n","history.history[\"test_accuracy\"] = test_acc\n","\n","print('test_acc:', test_acc)\n","print('test_loss:', test_loss)"],"metadata":{"id":"23J94TSMx-aT"},"execution_count":null,"outputs":[]}]}